# main.py â€“ Orchestrates full ETL pipeline
import os
import sys

# âœ… Ensure project root is on path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# âœ… Force PySpark to use Python 3.11
os.environ["PYSPARK_PYTHON"] = r"C:\Users\croma\AppData\Local\Programs\Python\Python311\python.exe"
os.environ["PYSPARK_DRIVER_PYTHON"] = r"C:\Users\croma\AppData\Local\Programs\Python\Python311\python.exe"

import logging
logging.getLogger("py4j").setLevel(logging.ERROR)
logging.getLogger("pyspark").setLevel(logging.ERROR)

from scripts.extract import extract_data
from scripts.transform import transform_data
from scripts.load import load_to_postgres


def main():
    print("ðŸš€ Starting Retail Customer Insights ETL Pipeline...\n")

    # Extract
    print("ðŸ”¹ Step 1: Extracting data...")
    orders_df, customers_df, products_df, reviews_df = extract_data()
    print("âœ… Extraction complete.\n")

    # Transform
    print("ðŸ”¹ Step 2: Transforming data...")
    insights_df = transform_data(orders_df, customers_df, products_df, reviews_df)
    print("âœ… Transformation complete.\n")

    # Load
    print("ðŸ”¹ Step 3: Loading data to PostgreSQL...")
    load_to_postgres(insights_df)
    print("\nâœ… ETL Pipeline completed successfully! ðŸš€")


if __name__ == "__main__":
    main()
